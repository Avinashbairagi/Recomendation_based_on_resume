{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92f47229",
   "metadata": {},
   "source": [
    "# Importing libararies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff614f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "from nltk.stem import PorterStemmer,WordNetLemmatizer\n",
    "from sklearn.decomposition import TruncatedSVD, NMF\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e2f470",
   "metadata": {},
   "source": [
    "### Reading initial Dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca3dfb0",
   "metadata": {},
   "source": [
    "Here we have merged the resumes and job discription together becouse we are useing **topic_modeling** from the text \n",
    "so it will help us in increasing the accuracy of the model to build good topics for accurate pridiction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9db0bf92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Java Developer         84\n",
       "Sales                  83\n",
       "Testing                70\n",
       "Data Science           51\n",
       "Python Developer       48\n",
       "Web Designing          45\n",
       "Mechanical Engineer    40\n",
       "Automation Testing     26\n",
       "ux,designer            26\n",
       "Civil Engineer         24\n",
       "data,analyst           24\n",
       "Name: Jobs, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs_df = pd.read_csv(\"Merged_data.csv\")\n",
    "jobs_df.drop(\"Unnamed: 0\", inplace= True,axis = 1)\n",
    "jobs_df[\"Jobs\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365a6254",
   "metadata": {},
   "source": [
    "# Text prepocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61992cbf",
   "metadata": {},
   "source": [
    "In every **NLP** model we need basic text preprocessing here we are creating a function that will do all the text preprocesing such as **remove URLs** , **remove hashtags** , **Punctuations** , **remove extra whitespace** etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8972aeb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a program to clean Job description by removing URLS, Whitespace ,Punctuations , remove mentions\n",
    "# remove hashtags\n",
    "def clean_function(resumeText):\n",
    "    \"\"\" Cleaning / preprocessing text data\"\"\"\n",
    "    resumeText = re.sub('http\\S+\\s*', ' ', resumeText)  # remove URLs\n",
    "    resumeText = re.sub('RT|cc', ' ', resumeText)  # remove RT and cc\n",
    "    resumeText = re.sub('#\\S+', '', resumeText)  # remove hashtags\n",
    "    resumeText = re.sub('@\\S+', '  ', resumeText)  # remove mentions\n",
    "    resumeText = re.sub('[%s]' % re.escape(\"\"\"!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\"\"\"), ' ', resumeText)  # remove punctuations\n",
    "    resumeText = re.sub(r'[^\\x00-\\x7f]',r' ', resumeText) \n",
    "    resumeText = re.sub('\\s+', ' ', resumeText)  # remove extra whitespace\n",
    "    return resumeText"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef05b3f",
   "metadata": {},
   "source": [
    "# Tokenization and stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ddc3ff8",
   "metadata": {},
   "source": [
    "Here we are creating a function that will do preprocessing of text along with **stemming and tokenization** of the words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a4829f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After preprocessing the text data we do tokenization and stemming \n",
    "# Creating a program tp tokenize and stem our document\n",
    "def tokenize_stem(series):\n",
    "    \"\"\" Tokenization and stemming of documents\"\"\"\n",
    "    tokenizer =TreebankWordTokenizer()\n",
    "    stemmer = PorterStemmer()\n",
    "    series = series.apply(lambda x: x.replace(\"\\n\", ' '))\n",
    "    series = series.apply(lambda x: clean_function(x))    #text cleaning function/ Test preprocessing\n",
    "    series = series.apply(lambda x: tokenizer.tokenize(x))\n",
    "    series = series.apply(lambda x: [stemmer.stem(w) for w in x])\n",
    "    series = series.apply(lambda x: ' '.join(x))\n",
    "    return series "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff2ab2f",
   "metadata": {},
   "source": [
    "### Turning job Discription into series\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f16a613f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turning job Discription into series\n",
    "series = tokenize_stem(jobs_df[\"Job Description\"])\n",
    "# series[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35efc26",
   "metadata": {},
   "source": [
    "# Vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f72243",
   "metadata": {},
   "source": [
    "Converting documents of words into a word vectors with the help of **Tfidf**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "860dc972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. ... 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# Converting documents of words into a word vectors with the help of Tfidf\n",
    "# Vectorizing Document\n",
    "vec = TfidfVectorizer(stop_words= \"english\",)\n",
    "doc_words = vec.fit_transform(series)\n",
    "print(doc_words.A[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "746a5ff0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4499"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(doc_words.A[0]) #Total features creatrd by tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e44442",
   "metadata": {},
   "source": [
    "Here we are building **Topic Modeling** which took input as word vectors and creat topics on its onw, here we created **20 Topic with 6 itteration** this topics will be behave as a independent features for our classification models .\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc67fcbc",
   "metadata": {},
   "source": [
    "# Building Topic Modling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36ce3f3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_component:  (4499,)\n"
     ]
    }
   ],
   "source": [
    "# Here we are building a topic Modiling LSD with the help of TruncatedSVD.\n",
    "topic_m = TruncatedSVD(n_components=20, n_iter=6) #created topic_model with topic 20\n",
    "topic_m = topic_m.fit(doc_words) #fit and transformed tfidf vectors.\n",
    "doc_topic = topic_m.transform(doc_words)\n",
    "print(\"model_component: \",topic_m.components_[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3be5944",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 4499)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_m.components_.shape # Model with 20 topics and 4364 components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b2c8f1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Programs to display topic numbers and words inside topics\n",
    "def display_topics(model, feature_names, no_top_words, topic_names=None):\n",
    "    '''\n",
    "    displays topics and returns list of toppics\n",
    "    '''\n",
    "\n",
    "    topic_list = []\n",
    "    for i, topic in enumerate(model.components_):\n",
    "        if not topic_names or not topic_names[i]:\n",
    "            print(\"\\nTopic \", i)\n",
    "        else:\n",
    "            print(\"\\nTopic: '\",topic_names[i],\"'\")\n",
    "\n",
    "        print(\", \".join([feature_names[k]\n",
    "                       for k in topic.argsort()[:-no_top_words - 1:-1]]))\n",
    "        topic_list.append(\", \".join([feature_names[k]\n",
    "                       for k in topic.argsort()[:-no_top_words - 1:-1]]))\n",
    "    return model.components_, topic_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "70d1f5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Def function to dispay model component array , model, vectorizer,topic_list\n",
    "def return_topics(series, num_topics, no_top_words, model, vectorizer):\n",
    "    '''\n",
    "    returns document_topic matrix and topic modeling model\n",
    "    '''\n",
    "    #turn job into series\n",
    "    series = tokenize_stem(series)\n",
    "    #transform series into corpus\n",
    "    ex_label = [e[:30]+\"...\" for e in series]\n",
    "    #set vectorizer ngrams = (2,2)\n",
    "    vec = vectorizer(stop_words = 'english')\n",
    "\n",
    "    doc_word = vec.fit_transform(series)\n",
    "\n",
    "    #build model\n",
    "    def_model = model(num_topics)\n",
    "    def_model = def_model.fit(doc_word)\n",
    "    doc_topic = def_model.transform(doc_word)\n",
    "    #print('model components: ', def_model.components_[0].shape)\n",
    "    #print('doc_topic', doc_topic[0])\n",
    "    model_components, topic_list = display_topics(def_model, vec.get_feature_names(), no_top_words)\n",
    "    return def_model.components_, doc_topic, def_model, vec, topic_list#, topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "86c05d33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic  0\n",
      "exprienc, month, test, java, develop, project, design, year, sale, python\n",
      "\n",
      "Topic  1\n",
      "java, exprienc, month, ajax, develop, spring, j2ee, jqueri, jsp, servlet\n",
      "\n",
      "Topic  2\n",
      "test, transform, window, java, check, autom, android, maharashtra, xp, manual\n",
      "\n",
      "Topic  3\n",
      "applic, project, ui, design, trust, photoshop, loan, role, websit, respons\n",
      "\n",
      "Topic  4\n",
      "pune, python, engin, mechan, januari, maharashtra, design, civil, june, project\n",
      "\n",
      "Topic  5\n",
      "sale, exprienc, month, offic, manag, cricket, ms, loan, bajaj, januari\n",
      "\n",
      "Topic  6\n",
      "python, data, month, exprienc, year, scienc, django, learn, rest, test\n",
      "\n",
      "Topic  7\n",
      "machin, mechan, data, exprienc, nagpur, plaster, engin, civil, month, android\n",
      "\n",
      "Topic  8\n",
      "electron, data, pcb, matlab, januari, qualiti, technolog, matrix, electr, 2010\n",
      "\n",
      "Topic  9\n",
      "electron, year, qualiti, exprienc, pcb, month, assembl, complet, nashik, hardwar\n",
      "\n",
      "Topic  10\n",
      "check, data, electr, resist, juli, scienc, good, analyt, ui, ir\n",
      "\n",
      "Topic  11\n",
      "use, pune, pcb, bootstrap, jqueri, matrix, matlab, synopsi, softwar, basic\n",
      "\n",
      "Topic  12\n",
      "allahabad, design, salari, uttar, net, pradesh, cricket, web, contract, year\n",
      "\n",
      "Topic  13\n",
      "check, civil, resist, ir, breaker, site, transform, circuit, insul, ajax\n",
      "\n",
      "Topic  14\n",
      "bootstrap, jqueri, use, synopsi, electr, 24, vidyalaya, kopargaon, msbte, intelux\n",
      "\n",
      "Topic  15\n",
      "android, complaint, crime, nagpur, cyber, train, m3, electr, 12, civil\n",
      "\n",
      "Topic  16\n",
      "transform, civil, inspect, learn, industri, jqueri, core, assembl, pune, data\n",
      "\n",
      "Topic  17\n",
      "presid, mechan, mit, associ, student, car, electron, m3, year, rest\n",
      "\n",
      "Topic  18\n",
      "check, 2017, secondari, electron, nagpur, resist, android, sql, suggest, merchant\n",
      "\n",
      "Topic  19\n",
      "machin, cnc, plaster, industri, check, nagpur, cad, train, semist, agro\n"
     ]
    }
   ],
   "source": [
    "array, doc, topic_model, vec, topic_list  = return_topics(jobs_df['Job Description'],20, 10, TruncatedSVD, TfidfVectorizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "138dc3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a new dataFrame with individual features are topics from topic modeling and dependent feature is jobs.\n",
    "\n",
    "# Creating Dataframe for predictive model\n",
    "# topic_df = pd.DataFrame(doc)\n",
    "# topic_df.columns = ['Topic ' + str(i+1) for i in range(len(topic_df.columns)) ]\n",
    "# topic_df['job'] = jobs_df.Jobs\n",
    "# topic_df.to_csv('merged_topic.csv') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375b69b0",
   "metadata": {},
   "source": [
    "Here we created our final data set for our classification model , i suggest u to use different classification models in my case **Random_forest worked well**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "19165879",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic 1</th>\n",
       "      <th>Topic 2</th>\n",
       "      <th>Topic 3</th>\n",
       "      <th>Topic 4</th>\n",
       "      <th>Topic 5</th>\n",
       "      <th>Topic 6</th>\n",
       "      <th>Topic 7</th>\n",
       "      <th>Topic 8</th>\n",
       "      <th>Topic 9</th>\n",
       "      <th>Topic 10</th>\n",
       "      <th>...</th>\n",
       "      <th>Topic 12</th>\n",
       "      <th>Topic 13</th>\n",
       "      <th>Topic 14</th>\n",
       "      <th>Topic 15</th>\n",
       "      <th>Topic 16</th>\n",
       "      <th>Topic 17</th>\n",
       "      <th>Topic 18</th>\n",
       "      <th>Topic 19</th>\n",
       "      <th>Topic 20</th>\n",
       "      <th>job</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.262339</td>\n",
       "      <td>-0.014537</td>\n",
       "      <td>-0.105785</td>\n",
       "      <td>-0.028614</td>\n",
       "      <td>0.016251</td>\n",
       "      <td>-0.291180</td>\n",
       "      <td>0.147528</td>\n",
       "      <td>0.046010</td>\n",
       "      <td>0.103826</td>\n",
       "      <td>-0.024114</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032609</td>\n",
       "      <td>-0.044105</td>\n",
       "      <td>0.069617</td>\n",
       "      <td>0.086200</td>\n",
       "      <td>-0.075034</td>\n",
       "      <td>0.072364</td>\n",
       "      <td>0.063650</td>\n",
       "      <td>0.044822</td>\n",
       "      <td>-0.057010</td>\n",
       "      <td>Data Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.235786</td>\n",
       "      <td>0.071434</td>\n",
       "      <td>-0.053580</td>\n",
       "      <td>-0.108751</td>\n",
       "      <td>0.028166</td>\n",
       "      <td>0.029274</td>\n",
       "      <td>0.238226</td>\n",
       "      <td>0.154460</td>\n",
       "      <td>0.046054</td>\n",
       "      <td>0.094442</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.026736</td>\n",
       "      <td>0.034899</td>\n",
       "      <td>-0.004818</td>\n",
       "      <td>0.043134</td>\n",
       "      <td>-0.050834</td>\n",
       "      <td>0.022262</td>\n",
       "      <td>0.022838</td>\n",
       "      <td>0.049669</td>\n",
       "      <td>-0.039426</td>\n",
       "      <td>Data Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.359566</td>\n",
       "      <td>0.103821</td>\n",
       "      <td>-0.019467</td>\n",
       "      <td>-0.182431</td>\n",
       "      <td>0.097349</td>\n",
       "      <td>0.019818</td>\n",
       "      <td>0.237412</td>\n",
       "      <td>0.067296</td>\n",
       "      <td>0.116512</td>\n",
       "      <td>0.083251</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.063437</td>\n",
       "      <td>0.015713</td>\n",
       "      <td>0.007060</td>\n",
       "      <td>0.071733</td>\n",
       "      <td>-0.013021</td>\n",
       "      <td>-0.039319</td>\n",
       "      <td>0.063786</td>\n",
       "      <td>0.029918</td>\n",
       "      <td>-0.043142</td>\n",
       "      <td>Data Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.342101</td>\n",
       "      <td>-0.053513</td>\n",
       "      <td>-0.100499</td>\n",
       "      <td>-0.017645</td>\n",
       "      <td>0.011028</td>\n",
       "      <td>-0.224039</td>\n",
       "      <td>0.173264</td>\n",
       "      <td>0.058909</td>\n",
       "      <td>0.043988</td>\n",
       "      <td>0.010256</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.055015</td>\n",
       "      <td>-0.065209</td>\n",
       "      <td>0.017938</td>\n",
       "      <td>0.057563</td>\n",
       "      <td>-0.064367</td>\n",
       "      <td>-0.003682</td>\n",
       "      <td>0.011635</td>\n",
       "      <td>0.052728</td>\n",
       "      <td>-0.052765</td>\n",
       "      <td>Data Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.387734</td>\n",
       "      <td>0.218800</td>\n",
       "      <td>-0.033395</td>\n",
       "      <td>-0.186137</td>\n",
       "      <td>-0.031608</td>\n",
       "      <td>0.107499</td>\n",
       "      <td>0.341216</td>\n",
       "      <td>0.187209</td>\n",
       "      <td>0.072586</td>\n",
       "      <td>0.179337</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018439</td>\n",
       "      <td>0.051923</td>\n",
       "      <td>-0.025246</td>\n",
       "      <td>0.048195</td>\n",
       "      <td>-0.024963</td>\n",
       "      <td>0.025634</td>\n",
       "      <td>0.052697</td>\n",
       "      <td>0.045288</td>\n",
       "      <td>-0.173923</td>\n",
       "      <td>Data Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>0.235412</td>\n",
       "      <td>-0.143217</td>\n",
       "      <td>-0.170880</td>\n",
       "      <td>-0.050714</td>\n",
       "      <td>-0.010634</td>\n",
       "      <td>-0.284425</td>\n",
       "      <td>0.069923</td>\n",
       "      <td>0.095856</td>\n",
       "      <td>0.068074</td>\n",
       "      <td>-0.013810</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038280</td>\n",
       "      <td>-0.006338</td>\n",
       "      <td>0.003024</td>\n",
       "      <td>-0.018697</td>\n",
       "      <td>0.017793</td>\n",
       "      <td>0.004649</td>\n",
       "      <td>0.002119</td>\n",
       "      <td>-0.027679</td>\n",
       "      <td>-0.088679</td>\n",
       "      <td>Data Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>0.175965</td>\n",
       "      <td>-0.093753</td>\n",
       "      <td>-0.131596</td>\n",
       "      <td>-0.038796</td>\n",
       "      <td>0.029315</td>\n",
       "      <td>-0.244000</td>\n",
       "      <td>0.078209</td>\n",
       "      <td>0.068859</td>\n",
       "      <td>0.069110</td>\n",
       "      <td>0.013058</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013157</td>\n",
       "      <td>0.001362</td>\n",
       "      <td>0.004671</td>\n",
       "      <td>-0.030603</td>\n",
       "      <td>-0.016305</td>\n",
       "      <td>0.024579</td>\n",
       "      <td>-0.016979</td>\n",
       "      <td>0.008965</td>\n",
       "      <td>-0.047603</td>\n",
       "      <td>Data Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>0.247148</td>\n",
       "      <td>-0.187813</td>\n",
       "      <td>-0.185143</td>\n",
       "      <td>-0.081691</td>\n",
       "      <td>-0.037593</td>\n",
       "      <td>-0.263858</td>\n",
       "      <td>0.087064</td>\n",
       "      <td>0.095161</td>\n",
       "      <td>0.059386</td>\n",
       "      <td>-0.019152</td>\n",
       "      <td>...</td>\n",
       "      <td>0.053166</td>\n",
       "      <td>0.016870</td>\n",
       "      <td>-0.007275</td>\n",
       "      <td>-0.029939</td>\n",
       "      <td>0.019934</td>\n",
       "      <td>0.010247</td>\n",
       "      <td>-0.008598</td>\n",
       "      <td>-0.039058</td>\n",
       "      <td>-0.100412</td>\n",
       "      <td>Data Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>0.252654</td>\n",
       "      <td>-0.164322</td>\n",
       "      <td>-0.205087</td>\n",
       "      <td>-0.097670</td>\n",
       "      <td>0.020609</td>\n",
       "      <td>-0.317458</td>\n",
       "      <td>0.129338</td>\n",
       "      <td>0.133066</td>\n",
       "      <td>0.123531</td>\n",
       "      <td>-0.017406</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011619</td>\n",
       "      <td>-0.032782</td>\n",
       "      <td>0.033246</td>\n",
       "      <td>-0.008420</td>\n",
       "      <td>-0.036806</td>\n",
       "      <td>0.032929</td>\n",
       "      <td>0.002773</td>\n",
       "      <td>0.015592</td>\n",
       "      <td>-0.065947</td>\n",
       "      <td>Data Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>0.209668</td>\n",
       "      <td>-0.125432</td>\n",
       "      <td>-0.144147</td>\n",
       "      <td>-0.040702</td>\n",
       "      <td>0.016212</td>\n",
       "      <td>-0.233737</td>\n",
       "      <td>0.038852</td>\n",
       "      <td>0.089999</td>\n",
       "      <td>0.087319</td>\n",
       "      <td>-0.023651</td>\n",
       "      <td>...</td>\n",
       "      <td>0.040687</td>\n",
       "      <td>-0.007647</td>\n",
       "      <td>0.034010</td>\n",
       "      <td>-0.019450</td>\n",
       "      <td>-0.007051</td>\n",
       "      <td>0.011759</td>\n",
       "      <td>0.008982</td>\n",
       "      <td>0.012665</td>\n",
       "      <td>-0.026042</td>\n",
       "      <td>Data Science</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>521 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Topic 1   Topic 2   Topic 3   Topic 4   Topic 5   Topic 6   Topic 7  \\\n",
       "0    0.262339 -0.014537 -0.105785 -0.028614  0.016251 -0.291180  0.147528   \n",
       "1    0.235786  0.071434 -0.053580 -0.108751  0.028166  0.029274  0.238226   \n",
       "2    0.359566  0.103821 -0.019467 -0.182431  0.097349  0.019818  0.237412   \n",
       "3    0.342101 -0.053513 -0.100499 -0.017645  0.011028 -0.224039  0.173264   \n",
       "4    0.387734  0.218800 -0.033395 -0.186137 -0.031608  0.107499  0.341216   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "516  0.235412 -0.143217 -0.170880 -0.050714 -0.010634 -0.284425  0.069923   \n",
       "517  0.175965 -0.093753 -0.131596 -0.038796  0.029315 -0.244000  0.078209   \n",
       "518  0.247148 -0.187813 -0.185143 -0.081691 -0.037593 -0.263858  0.087064   \n",
       "519  0.252654 -0.164322 -0.205087 -0.097670  0.020609 -0.317458  0.129338   \n",
       "520  0.209668 -0.125432 -0.144147 -0.040702  0.016212 -0.233737  0.038852   \n",
       "\n",
       "      Topic 8   Topic 9  Topic 10  ...  Topic 12  Topic 13  Topic 14  \\\n",
       "0    0.046010  0.103826 -0.024114  ...  0.032609 -0.044105  0.069617   \n",
       "1    0.154460  0.046054  0.094442  ... -0.026736  0.034899 -0.004818   \n",
       "2    0.067296  0.116512  0.083251  ... -0.063437  0.015713  0.007060   \n",
       "3    0.058909  0.043988  0.010256  ... -0.055015 -0.065209  0.017938   \n",
       "4    0.187209  0.072586  0.179337  ... -0.018439  0.051923 -0.025246   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "516  0.095856  0.068074 -0.013810  ...  0.038280 -0.006338  0.003024   \n",
       "517  0.068859  0.069110  0.013058  ...  0.013157  0.001362  0.004671   \n",
       "518  0.095161  0.059386 -0.019152  ...  0.053166  0.016870 -0.007275   \n",
       "519  0.133066  0.123531 -0.017406  ...  0.011619 -0.032782  0.033246   \n",
       "520  0.089999  0.087319 -0.023651  ...  0.040687 -0.007647  0.034010   \n",
       "\n",
       "     Topic 15  Topic 16  Topic 17  Topic 18  Topic 19  Topic 20           job  \n",
       "0    0.086200 -0.075034  0.072364  0.063650  0.044822 -0.057010  Data Science  \n",
       "1    0.043134 -0.050834  0.022262  0.022838  0.049669 -0.039426  Data Science  \n",
       "2    0.071733 -0.013021 -0.039319  0.063786  0.029918 -0.043142  Data Science  \n",
       "3    0.057563 -0.064367 -0.003682  0.011635  0.052728 -0.052765  Data Science  \n",
       "4    0.048195 -0.024963  0.025634  0.052697  0.045288 -0.173923  Data Science  \n",
       "..        ...       ...       ...       ...       ...       ...           ...  \n",
       "516 -0.018697  0.017793  0.004649  0.002119 -0.027679 -0.088679  Data Science  \n",
       "517 -0.030603 -0.016305  0.024579 -0.016979  0.008965 -0.047603  Data Science  \n",
       "518 -0.029939  0.019934  0.010247 -0.008598 -0.039058 -0.100412  Data Science  \n",
       "519 -0.008420 -0.036806  0.032929  0.002773  0.015592 -0.065947  Data Science  \n",
       "520 -0.019450 -0.007051  0.011759  0.008982  0.012665 -0.026042  Data Science  \n",
       "\n",
       "[521 rows x 21 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# From vectors of topic modling and df[Job] we created our new datafreame to predict accuracy.\n",
    "df1 = pd.read_csv('merged_topic.csv')\n",
    "df1.drop(\"Unnamed: 0\",axis = 1,inplace= True)\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2836ae",
   "metadata": {},
   "source": [
    "# Predictive model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f71ae9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df1.drop(\"job\",axis = 1)\n",
    "y = df1[\"job\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "68614a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitinf data for training amd testing.\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,random_state= 1,test_size= .3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bd2966c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(364, 20)\n",
      "(364,)\n",
      "(157, 20)\n",
      "(157,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "340136ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_accuracy:  0.9780441400304415\n",
      "Testing_accuracy:  0.9808917197452229\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(x_train, y_train)\n",
    "print('Training_accuracy: ', np.mean(cross_val_score(rfc, x_train, y_train, scoring = 'accuracy', cv=5)))\n",
    "print('Testing_accuracy: ', accuracy_score(y_test, rfc.predict(x_test)))\n",
    "# print(rfc.predict(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021f50ee",
   "metadata": {},
   "source": [
    "# Hyper parameter tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "269658fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 9, 'n_estimators': 400}\n"
     ]
    }
   ],
   "source": [
    "# param_grid = {'n_estimators': [100,300, 400, 500, 600], 'max_depth': [3,7,9, 11]}\n",
    "# search = GridSearchCV(RandomForestClassifier(), param_grid, cv=5)\n",
    "# search.fit(x_train, y_train)\n",
    "# best_parameters = search.best_params_\n",
    "# print(best_parameters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e9efe6b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_accuracy:  0.9807838660578387\n",
      "Testing_accuracy:  0.9808917197452229\n"
     ]
    }
   ],
   "source": [
    "# Created new Prediction models with best parameters \n",
    "rfc = RandomForestClassifier(n_estimators = 400, max_depth = 9)\n",
    "rfc.fit(x_train, y_train)\n",
    "print('Training_accuracy: ', np.mean(cross_val_score(rfc, x_train, y_train, scoring = 'accuracy', cv=5)))\n",
    "print('Testing_accuracy: ', accuracy_score(y_test, rfc.predict(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e7c655",
   "metadata": {},
   "source": [
    "Here we can see that after Hyper parameter tunning we got the **Accuracy of training -98 and testing - 98** so we can conclude that our model is working well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4903d252",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function which convert resume and give job pridiction probablities\n",
    "def predict_resume(topic_model, model, resume):\n",
    "    '''\n",
    "    transforms a resume based on the topic modeling model and return prediction probabilities per each job class\n",
    "    '''\n",
    "    doc = topic_model.transform(resume) # frist preprocess data into array and then transform to \n",
    "    return model.predict_proba(doc), model.classes_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7cbde18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic_classification_models():\n",
    "    jobs_df, model, vec , topic_list= process_data()\n",
    "    model_1 = predictive_modeling(jobs_df)\n",
    "    return model, model_1, vec                      # Model_1 is rfs , model is TruncateSVD, vec is Tfidf\n",
    "# Pickling the model , classifier and vectors for future use.\n",
    "# topic_model, classifier, vec= get_topic_classification_models()\n",
    "# topic_model_name = 'topic_model.sav'\n",
    "# classifier_name = 'classification_model.sav'\n",
    "# vec_name = 'job_vec.sav'\n",
    "# pickle.dump(topic_model, open(topic_model_name, 'wb'))\n",
    "# pickle.dump(classifier, open(classifier_name, 'wb'))\n",
    "# pickle.dump(vec, open(vec_name, 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d6bc2df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Both this upper program requires for our final function to show resume matching jon probablities\n",
    "\n",
    "# Showing Resume matching job probablities\n",
    "\n",
    "def Show_prob(resume, topic_model, predictor, vec):\n",
    "    '''\n",
    "    run code that predicts resume\n",
    "    '''\n",
    "    #jobs_df, model, vec , topic_list= process_data()\n",
    "    #model_1 = predictive_modeling(jobs_df)\n",
    "    series =pd.Series(resume)\n",
    "    doc = tokenize_stem(series)\n",
    "    doc = vec.transform(doc)\n",
    "    probabilities, classes = predict_resume(topic_model, predictor, doc)\n",
    "    result = pd.DataFrame(zip(classes, probabilities[0]*100), columns = ['Jobs', 'Matching_Probablity'])\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6d987a",
   "metadata": {},
   "source": [
    "# Testing Sample Resume on our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fe9d54c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "manager = \"\"\"Administrative Assistant with 6+ years of experience preparing flawless presentations, assembling facility reports, and maintaining the utmost confidentiality. Possesses a B.A. in History and expertise in Microsoft Excel. \n",
    "Looking to leverage my knowledge and experience into a role as Project Manager.\n",
    "\n",
    "Professional Experience\n",
    "\n",
    "ADMINISTRATIVE ASSISTANT\n",
    "REDFORD & SONS – Chicago, IL \n",
    "SEP 2019  \n",
    " –  Present\n",
    "    • Schedule and coordinate meetings, appointments, and travel arrangements for supervisors and managers\n",
    "    • Trained 2 administrative assistants during a period of company expansion to ensure attention to detail and adherence to company\n",
    "    • Developed new filing and organizational practices, saving the company $3,000 per year in contracted labor expenses\n",
    "    • Maintain utmost discretion when dealing with sensitive topics\n",
    "    • Manage travel and expense reports for department team members\n",
    "SECRETARY\n",
    "BRIGHT SPOT LTD – Boston, MA \n",
    "JUN 2017\n",
    "–  AUG 2019\n",
    "    • Type documents such as correspondence, drafts, memos, and emails, and prepared 3 reports weekly for management\n",
    "    • Opened, sorted, and distributed incoming messages and correspondence\n",
    "    • Purchased and maintained office suppled inventories, and always carefully adhered to budgeting practices\n",
    "    • Greeted visitors and helped them either find the appropriate person or schedule an appointment\n",
    "    • Recorded, transcribed, and distributed minutes of meetings\n",
    "SECRETARY\n",
    "SUNTRUST FINANCIAL – Chicago, IL \n",
    "JUN 2015 \n",
    "– AUG 2017\n",
    "    • Recorded, transcribed and distributed weekly meetings\n",
    "    • Answered upwards of 20 phone calls daily, taking detailed messages\n",
    "    • Arranged appointments and ensured executives arrived to meetings with \n",
    "clients on time\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b6f9109a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Jobs</th>\n",
       "      <th>Matching_Probablity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Automation Testing</td>\n",
       "      <td>8.028101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Civil Engineer</td>\n",
       "      <td>1.787866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>1.948770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Java Developer</td>\n",
       "      <td>5.767912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mechanical Engineer</td>\n",
       "      <td>2.220644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Python Developer</td>\n",
       "      <td>1.047715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sales</td>\n",
       "      <td>47.631957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Testing</td>\n",
       "      <td>9.916923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Web Designing</td>\n",
       "      <td>1.260440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>data,analyst</td>\n",
       "      <td>12.854215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ux,designer</td>\n",
       "      <td>7.535456</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Jobs  Matching_Probablity\n",
       "0    Automation Testing             8.028101\n",
       "1        Civil Engineer             1.787866\n",
       "2          Data Science             1.948770\n",
       "3        Java Developer             5.767912\n",
       "4   Mechanical Engineer             2.220644\n",
       "5      Python Developer             1.047715\n",
       "6                 Sales            47.631957\n",
       "7               Testing             9.916923\n",
       "8         Web Designing             1.260440\n",
       "9          data,analyst            12.854215\n",
       "10          ux,designer             7.535456"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Show_prob(manager,topic_m,rfc,vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "441f721a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ux = \"\"\"EXPERTISE\n",
    "Design Strategy, User Experience, Information Architecture, Usability, UI flows, Web / Mobile / Tablet application Design, Wireframe & Mockup Development, Rapid Prototyping, Visual Design, Corporate Branding\n",
    "TOOLS\n",
    "Fireworks, Photoshop, Illustrator, Flash, Dreamweaver, InDesign, OmniGraffle, HTML, CSS, JS\n",
    "EXPERIENCE\n",
    "Sr. UX Designer | Confidential,Mountain View, CA | 06/11 – Present\n",
    "• Collaborated with Product Owners and multiple Design teams across the company\n",
    "• Re-designed the UI and design patterns of an acquired product (zavers) to align with Google brand & products\n",
    "• Presented design strategies at the UX reviews to the higher management\n",
    "• Completed end-to-end Google coupons phase 1.0 design for both web and mobile \n",
    "• Initiated Google coupons phase 2.0 re-design for tighter integration with Google wallet and offers\n",
    "Lead UX Designer | Confidential,San Francisco, CA | 04/10 – 06/11 \n",
    "• Brainstormed and implemented UI solutions for various projects and multiple teams both local and remote\n",
    "• As a CX lead I’d collaborated with User Researchers, Visual Designers and Content Strategists \n",
    "• Designed a common platform for legacy Wachovia users migrating to Wells Fargo for “Check Recovery Service” tool \n",
    "• Redesigned the “Mortgage Product Recommendation Tool”, also helped creating mockups and prototyped using Flash Catalyst for Usability Study\n",
    "Sr. UX Designer | Confidential,San Jose, CA | 09/09 – 02/10 \n",
    "• Worked with multiple Business units to create usable solutions for various projects \n",
    "• Redesigned AdCommerce UI flows and visual design for the pilot launch \n",
    "• Analyzed, implemented and revised designs based on research findings \n",
    "• Automated the existing manual Unpaid Item, also created UI and visuals for the same \n",
    "• Worked closely with the design standards group to stay compliant with eBay patterns\n",
    "Lead UX Designer | Confidential,Redwood City, CA | 09/08 - 09/09 \n",
    "• Worked closely with the Business & Product team to analyze project requirements \n",
    "• Defined page schematics to guide product decision making & Engineering development \n",
    "• Initiated User research, Usability & Concept testing \n",
    "• Created UI sketches, flows, wireframes & rapid prototypes for Web & Mobile platforms \n",
    "• Designed UI solutions for internal product & partners (e.g. Citi, MasterCard & Nokia)\n",
    "Sr. UX Designer | Confidential,San Jose, CA | 06/07 - 09/08 \n",
    "• Collaborated with cross-functional teams to provide UX support \n",
    "• Created wireframes, visual assets and high fidelity mockups \n",
    "• Designed the Virtual Terminal & Store Front applications for Merchant Services \n",
    "• Designed the Global Seller Registration signup process for Market Places \n",
    "• Reworked the Large & Small Merchant Business implementation guide per PayPal \n",
    "branding & also delivered UED spec for various projects\n",
    "Sr. UI Developer | Confidential,Austin, TX | 09/04 - 05/07 \n",
    "• Designed/maintained Visa Information Management Portal & other Financial portlets \n",
    "• Worked with Product Office to define new requirements \n",
    "• Develop and Prototype interaction while consulting with development team for feasibility \n",
    "• Coded & Drove static demos & implement feedback from Business Users \n",
    "• Tested application for business rules accuracy during post implementation cycle also created “Demo Videos” to support internationalization\n",
    "Interactive Designer| Confidential,Atlanta, GA | 05/04 - 09/04 \n",
    "• Gathered & Reviewed project requirements from Product Owners \n",
    "• Developed Flash based Interactive tutorials (CBT/WBT’s) \n",
    "• Created design templates & Interfaces \n",
    "• Audio & Video Editing\n",
    "Lead Web Designer | Confidential,Chennai, India | 05/02 - 05/04 \n",
    "• Developed & Designed Flash, Static & Dynamic Websites \n",
    "• Designed Corporate Identity, branding & Marketing materials \n",
    "• Design Team management, training & documentation \n",
    "• Communicated directly with End-Clients & Offshore Team\n",
    "Creative Visualizer | Confidential,Chennai, India | 06/00 - 04/02 \n",
    "• Brainstorm, Iterate & Storyboard creative design solutions \n",
    "• Visualize & Design for the Web & Print \n",
    "• Created User-Friendly interface, optimized for quick downloads \n",
    "• Chose Optimal Technology for Scalability and Speed, Single-Click access to information and concise content\n",
    "Freelancer | Confidential,Oxfordshire, UK | 10/02 - 02/03 \n",
    "• Designed Solutions for Online Business Promotion \n",
    "• Marketing Design Support targeting increase in seasonal promotions \n",
    "• Designed Mailers, Banners & Print collaterals for in-house & affiliates \n",
    "• Seasonal Website Updates and Maintenance\n",
    "EDUCATION\n",
    "Certified Usability Analyst\n",
    "Bachelor of Information Technology\n",
    "Diploma in Graphic Arts\n",
    "Diploma in Digital Pre-Press\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "eb550019",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Jobs</th>\n",
       "      <th>Matching_Probablity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Automation Testing</td>\n",
       "      <td>3.990327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Civil Engineer</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>3.158514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Java Developer</td>\n",
       "      <td>1.791667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mechanical Engineer</td>\n",
       "      <td>5.908929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Python Developer</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sales</td>\n",
       "      <td>6.767857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Testing</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Web Designing</td>\n",
       "      <td>7.537558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>data,analyst</td>\n",
       "      <td>8.358631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ux,designer</td>\n",
       "      <td>59.861517</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Jobs  Matching_Probablity\n",
       "0    Automation Testing             3.990327\n",
       "1        Civil Engineer             0.000000\n",
       "2          Data Science             3.158514\n",
       "3        Java Developer             1.791667\n",
       "4   Mechanical Engineer             5.908929\n",
       "5      Python Developer             0.625000\n",
       "6                 Sales             6.767857\n",
       "7               Testing             2.000000\n",
       "8         Web Designing             7.537558\n",
       "9          data,analyst             8.358631\n",
       "10          ux,designer            59.861517"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Show_prob(ux,topic_m,rfc,vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "40c123a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = \"\"\"Trish Mathers\n",
    "Entry-Level Data Scientist\n",
    "Innovative and scientiﬁcally rigorous recent graduate with a signiﬁcant data science internship experience to bring to the table. With a team-oriented attitude, I am eager to contribute my abilities in quantitative modeling and experimentation to enhance the experience of Pinterest users around the world.\n",
    "tmathers@email.com (123) 456-7890\n",
    "Bellevue, WA LinkedIn\n",
    "\n",
    "WORK EXPERIENCE\n",
    "Niantic\n",
    "Data Scientist Intern\n",
    "Seattle, WA | April 2020 - April 2021\n",
    "    • Developed a program in SAS that automated reﬁnement of linear regression models for speciﬁc segments of a customer base that saved\n",
    "22 hours of labor per month.\n",
    "    • Received, cleaned, and prepped data from client using SAS, SQL, and Excel to help data scientists build marketing mix models that resulted in\n",
    "a lift in ROI of 10 basis points.\n",
    "\n",
    "Seattle University Tutor Center\n",
    "Statistics and Mathematics Tutor\n",
    "Seattle, WA | April 2019 - April 2020\n",
    "    • Assessed students' learning to determine learning weaknesses and needs, successfully helping students perform 13% better in algebra, pre-\n",
    "calculus, calculus, and statistics undergraduate courses.\n",
    "    • Met with 30+ students per week through online learning platforms or in a 1:1 setting at the tutor center.\n",
    "    • Scheduled weekly appointments for students, and set schedules for student statistics and math tutors.\n",
    "    • Communicated with professors about curriculum, and submitted reports 2 times per week to maintain up-to-date learning plans for students.\n",
    "\n",
    "PROJECTS\n",
    "Fantasy Football Models\n",
    "    • Aggregated and prepped 3 years of fantasy football projection data from 3 independent sources into a MySQL database.\n",
    "    • Created a random forest model in SAS, combining disparate sources into one projection that outperformed the mean absolute error of the next\n",
    "best projection by 15%.\n",
    "\n",
    "Entertainment Engine\n",
    "    • Aggregated data from IMDB and Rotten Tomatoes, and used k-nearest- neighbors in SAS, constructing an enhanced entertainment selection\n",
    "targeted to reach 15- to 25-year-olds.\n",
    "    • Improved methodologies to save an average of 12 minutes per movie selection and 3 minutes per song selection.\n",
    "SKILLS\n",
    "    • Programming: SAS (base SAS and Macros), SQL\n",
    "    • Supervised Learning: linear and logistic regressions,\n",
    "decision trees, support vector machines (SVM)\n",
    "    • Unsupervised Learning: k- means clustering, principal\n",
    "component analysis (PCA)\n",
    "    • Data Visualization: Excel, Google Sheets\n",
    "\n",
    "EDUCATION\n",
    "B.S.\n",
    "Mathematics and Economics Seattle University\n",
    "September 2017 - April 2021 Seattle, WA\n",
    "GPA: 3.7\n",
    "\n",
    "RELEVANT COURSES\n",
    "    • Intermediate programming\n",
    "    • Probability & Statistics\n",
    "    • Linear Algebra\n",
    "    • Applied Econometrics\n",
    "    • Game Theory\n",
    "    • Calculus 1-3\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9d911668",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Jobs</th>\n",
       "      <th>Matching_Probablity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Automation Testing</td>\n",
       "      <td>2.503261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Civil Engineer</td>\n",
       "      <td>2.936322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>42.163140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Java Developer</td>\n",
       "      <td>0.443182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mechanical Engineer</td>\n",
       "      <td>1.212121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Python Developer</td>\n",
       "      <td>1.310307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sales</td>\n",
       "      <td>1.555156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Testing</td>\n",
       "      <td>0.873750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Web Designing</td>\n",
       "      <td>1.186368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>data,analyst</td>\n",
       "      <td>38.726088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ux,designer</td>\n",
       "      <td>7.090305</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Jobs  Matching_Probablity\n",
       "0    Automation Testing             2.503261\n",
       "1        Civil Engineer             2.936322\n",
       "2          Data Science            42.163140\n",
       "3        Java Developer             0.443182\n",
       "4   Mechanical Engineer             1.212121\n",
       "5      Python Developer             1.310307\n",
       "6                 Sales             1.555156\n",
       "7               Testing             0.873750\n",
       "8         Web Designing             1.186368\n",
       "9          data,analyst            38.726088\n",
       "10          ux,designer             7.090305"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Show_prob(ds,topic_m,rfc,vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6a44f632",
   "metadata": {},
   "outputs": [],
   "source": [
    "anki = \"\"\"ANKIT DHANORE\n",
    "Seeking Data Scientist Position\n",
    "Phone no :- 7020276280\n",
    "Email\t:- ankitd08.job@gmail.com\n",
    "Address\t:- MQ 641, shubhash nagar, ghugus, chandrapur, maharashtra ,442505 . Github\t:- https://github.com/ankitd08/Personal-projects\n",
    "Linkedin   :-  https://www.linkedin.com/in/ankit-dhanore-a63970259\n",
    "ABOUT ME :\n",
    "\n",
    "Seeking a data scientist position to use my learnings to help the business meet strategic and operational goals by identifying opportunities to deploy new technology in data science. Possess expertise in Python & Data Analytics, ML, NLP, and DL modeling, and proven ability to manage complex tasks.\n",
    "PROFESSIONAL SYNOPSIS :\n",
    "Sound Understanding in AI and Machine Learning & DSA (Data Structures & Algorithms). Proficient in Core Python and its libraries and Modeling - regression, classification, linear etc. Proficient in building highly scalable and optimized engines for Data Analytics.\n",
    "Strong exposure in RDBMS (MySQL, MongoDB, Document DB, MSSQL) and Servers. Good in exposing and consuming APIs, RESTAPI, Web Services\n",
    "DATA SCIENCE, PYTHON & ML :\n",
    "\n",
    "\n",
    "Strong Python Programming skills using OOPS, Functions, Modularization & decorators. Sound Knowledge of Python’s Data Analysis and Machine Learning Libraries.\n",
    "Development of REST APIs in Python. Experience in Web Framework Flask. Implementation of regularization techniques like Lasso and Ridge in regression.\n",
    "Data mining algorithm experience in the families of predictive algorithms (Regression, KNN, Decision Trees) and clustering algorithms (k-means clustering).\n",
    "Ability to process Text Processing using NLTK library and other Natural Language .\n",
    "Thorough understanding of Probability and Statistics, Bayesian methods, Time Series analysis. Experience in data management tools – Non Relational and SQL databases.\n",
    "Ability to use Web Scraping Tools as Beautiful Soup.\n",
    "Source code management and Version Control system using Git and GitHub. Thorough understanding of supervised and unsupervised algorithms.\n",
    "SKILLS :\n",
    "Languages :- Python, SQL\n",
    "Framework and Libraries :- Flask, Numpy, Pandas, Matplotlib, Seaborn, Scikit-learn, Tensorflow, OpenCV, Scipy etc\n",
    "NLP and Deep Learning :- word2vec, word cloud, word embedding, Basic of Deep Learning and AWS. etc\n",
    "ML algorithms :- Linear and logistic Regression, KNN, Support vector machine, Naive Bayes, Decision Tree, Random Forest, Adaboost, hierarchicalclustering, k means clustering.\n",
    "STRENGTHS :\n",
    "Ability to write a clean and production code with Object Oriented Programming in Python. Able to investigate Data Visualization and summarization techniques conveying key findings\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e7836277",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Jobs</th>\n",
       "      <th>Matching_Probablity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Automation Testing</td>\n",
       "      <td>0.517857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Civil Engineer</td>\n",
       "      <td>1.521739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>83.446518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Java Developer</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mechanical Engineer</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Python Developer</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sales</td>\n",
       "      <td>0.259615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Testing</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Web Designing</td>\n",
       "      <td>0.910714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>data,analyst</td>\n",
       "      <td>6.707686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ux,designer</td>\n",
       "      <td>2.760870</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Jobs  Matching_Probablity\n",
       "0    Automation Testing             0.517857\n",
       "1        Civil Engineer             1.521739\n",
       "2          Data Science            83.446518\n",
       "3        Java Developer             0.625000\n",
       "4   Mechanical Engineer             0.750000\n",
       "5      Python Developer             2.000000\n",
       "6                 Sales             0.259615\n",
       "7               Testing             0.500000\n",
       "8         Web Designing             0.910714\n",
       "9          data,analyst             6.707686\n",
       "10          ux,designer             2.760870"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Show_prob(anki,topic_m,rfc,vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "72fd550b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales = \"\"\"Handled all client relations and sales for portfolio of 70-80 accounts. Conducted sales presentations to decision makers and generate quotes that meet each client’s needs. Worked effectively in remote and office settings while traveling ~50% of the time. Maintained in-depth knowledge of product and services portfolio.\n",
    "\n",
    "Awarded President’s Club in 2018, 2019, and 2020 for achieving over 105% of sales goal.\n",
    "Grew major client account by 50% by earning their trust and recommending service that solved one of their key problems.\n",
    "Sourced 10 new clients through cold calling and digital lead conversion.\n",
    "Organized monthly events to demonstrate products and services, building pipeline of over 600 prospective clients.\n",
    "Selected for and completed sales leadership development program.\n",
    "Promoted to invigorate stagnant sales growth and revitalize product launch/development. Managed $25M district P&L among 150 employees and 1.5K partners. Optimized retention strategies through renovating company value proposition to address clients’ changing needs. Maximized local resources and relationships to implement company-wide sales and marketing initiatives.\n",
    "\n",
    "Managed customer relationships with local distribution centers and partners to drive district sales before initial product launch.\n",
    "Achieved the highest district customer renewal rate, increasing 15% from prior year.\n",
    "Rebuilt continuing education and training resources for associate sales representatives, raising individual quota achievement 17% over two years.\n",
    "Oversee hiring, training and management of team of 15-20 sales representatives. Create strategy to continually achieve and exceed sales goals by prospecting clients and implementing effective sales processes. Directly manage key accounts and serve as escalation point for client issues and concerns.\n",
    "\n",
    "Achieved 105% of sales quota in 2019 and 102% in 2020.\n",
    "Introduced new coaching strategy for sales reps, creating customized plans that capitalize on individual strengths and motivators and holding monthly 1-on-1 meetings to review plan.\n",
    "Implemented Salesforce to track over 10,000 prospective clients and manage 500+ existing client accounts.\n",
    "Grew 5 major accounts by 30% by building client rapport and presenting solutions to client needs.\n",
    "Created new sales materials for current and upcoming products.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8b555d29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Jobs</th>\n",
       "      <th>Matching_Probablity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Automation Testing</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Civil Engineer</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>0.754032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Java Developer</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mechanical Engineer</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Python Developer</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sales</td>\n",
       "      <td>92.567396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Testing</td>\n",
       "      <td>1.678571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Web Designing</td>\n",
       "      <td>1.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>data,analyst</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ux,designer</td>\n",
       "      <td>1.250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Jobs  Matching_Probablity\n",
       "0    Automation Testing             0.250000\n",
       "1        Civil Engineer             0.250000\n",
       "2          Data Science             0.754032\n",
       "3        Java Developer             0.750000\n",
       "4   Mechanical Engineer             0.250000\n",
       "5      Python Developer             0.250000\n",
       "6                 Sales            92.567396\n",
       "7               Testing             1.678571\n",
       "8         Web Designing             1.250000\n",
       "9          data,analyst             0.750000\n",
       "10          ux,designer             1.250000"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Show_prob(sales,topic_m,rfc,vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "afc1f81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "civil = \"\"\"Earl Beckstrom\n",
    "Sometown, MI 48103\n",
    "Phone: (555) 555-5555\n",
    "Email: eb@somedomain.com | LinkedIn URL\n",
    "\n",
    "CIVIL ENGINEER\n",
    "\n",
    "Upcoming graduate of ABET-accredited bachelor’s in civil engineering program. Backed by successful internship experience and knowledge of engineering theories, principles, specifications and standards. Plan to earn Engineer in Training certification upon graduation.\n",
    "Demonstrated 3D skills with the ability to design site layouts from concept through completion. Proficient user of AutoCAD Civil 3D, MicroStation and ArcGIS.\n",
    "Knowledge of Sometown, MI Municipalities Planning Code and zoning, subdivision and storm water ordinances.\n",
    "Education & Credentials\n",
    "\n",
    "ABC UNIVERISTY, Sometown, MI\n",
    "Bachelor of Science in Civil Engineering program, 120/132 credits completed\n",
    "\n",
    "Honors: Chi Epsilon (Civil Engineering Honor Society), Dean’s List (5 semesters)\n",
    "Activities: Member, American Society of Civil Engineers and Emerging Green Builders (EGB); Planning Committee, Engineering Expo\n",
    "Course Highlights:\n",
    "Civil Engineering Design\n",
    "Cost Estimating & Surveying\n",
    "Structural Analysis & Dynamics\n",
    "Geotechnical Engineering\n",
    "Construction Methods\n",
    "Traffic & Materials Engineering\n",
    "Environmental Engineering\n",
    "Water Resource Engineering\n",
    "Fluid Mechanics & Hydraulics\n",
    "Concrete & Steel Design\n",
    "Professional Experience\n",
    "\n",
    "XYZ COMPANY, Sometown, MI\n",
    "Engineering firm serving government and commercial clients.\n",
    "Intern, Civil Engineering Group, September 2016 to Present\n",
    "\n",
    "Assisted civil engineers on several key government projects involving roadway designs and improvements, solutions easing traffic congestion and replacement of deteriorating bridges.\n",
    "Handled cost-of-materials estimations, report and document tracking, project documentation, on-site project visits, invoice/agreement verification and building permit applications.\n",
    "Gained experience in blueprint reading, as well as preparation of maps and plans.\n",
    "ABC COMPANY, Sometown, MI\n",
    "Worked in telesales throughout college to help finance education.\n",
    "Sales Representative, June 2014 to August 2016 (seasonal)\n",
    "\n",
    "Cold-called small business owners to sign new accounts for ABC Company’s print advertising service.\n",
    "Cultivated excellent relationships throughout assigned territory.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "af332f07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Jobs</th>\n",
       "      <th>Matching_Probablity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Automation Testing</td>\n",
       "      <td>6.452799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Civil Engineer</td>\n",
       "      <td>57.392628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Science</td>\n",
       "      <td>1.404942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Java Developer</td>\n",
       "      <td>1.859649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mechanical Engineer</td>\n",
       "      <td>16.202174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Python Developer</td>\n",
       "      <td>2.471404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sales</td>\n",
       "      <td>3.148549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Testing</td>\n",
       "      <td>1.227532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Web Designing</td>\n",
       "      <td>2.554762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>data,analyst</td>\n",
       "      <td>4.949601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ux,designer</td>\n",
       "      <td>2.335960</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Jobs  Matching_Probablity\n",
       "0    Automation Testing             6.452799\n",
       "1        Civil Engineer            57.392628\n",
       "2          Data Science             1.404942\n",
       "3        Java Developer             1.859649\n",
       "4   Mechanical Engineer            16.202174\n",
       "5      Python Developer             2.471404\n",
       "6                 Sales             3.148549\n",
       "7               Testing             1.227532\n",
       "8         Web Designing             2.554762\n",
       "9          data,analyst             4.949601\n",
       "10          ux,designer             2.335960"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Show_prob(civil,topic_m,rfc,vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e81d67c",
   "metadata": {},
   "source": [
    "### Checking imbalance of data for each catogeries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b041f047",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Java Developer         84\n",
       "Sales                  83\n",
       "Testing                70\n",
       "Data Science           51\n",
       "Python Developer       48\n",
       "Web Designing          45\n",
       "Mechanical Engineer    40\n",
       "Automation Testing     26\n",
       "ux,designer            26\n",
       "Civil Engineer         24\n",
       "data,analyst           24\n",
       "Name: Jobs, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs_df[\"Jobs\"].value_counts() # here we can see that job discription are imbalanced "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7bc0b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
